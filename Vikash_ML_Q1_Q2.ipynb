{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93016caf",
   "metadata": {},
   "source": [
    "Assignement 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06687cf4",
   "metadata": {},
   "source": [
    "**To find : P (C sunny/ a cone of ice-cream) = ? <br>\n",
    "P (rainy /a cup of hot coffee)=? <br>\n",
    "Given the occurrence of each word is Independent<br>\n",
    "P (a cone of ice cream) = P(a) (cone) P(of) P(ice) P(cream)** <br>\n",
    "**Part a)** <br>\n",
    "P(Sunny/a cone of ice cream) <br>\n",
    "_Using Bayes theorem :P(A/B) = (PB/A)*P(A)/P(B)_ <br>\n",
    "we can find <br>\n",
    "P (Sunny/a cone of Ice-cream) = P (a cone of Ice-cream/sunny) * (P (sunny)/ P(a cone of Ice-cream)) \n",
    "Also, since the words are independent: <br>\n",
    "**we want to classify the tags with higher probability, so ignoring the denominator** <br>\n",
    "therefore: - <br>\n",
    "P (Sunny/a cone of Ice-cream) = P(a/sunny) * P (Cone/sunny) * P (of/ sunny) * P(Ice/ sunny)* P (Cream/sunny)* P (Sunny)<br>\n",
    "\n",
    "**Part B)** <br>\n",
    "Similarly: -<br>\n",
    "P (rainy/a cup of hot coffee) = P(a/rainy).P(cup/rainy).P(of/rainy).P(hot/rainy).P(coffee/rainy).P(rainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c6d3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclassificationMethod\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import classificationMethod\n",
    "import math\n",
    "\n",
    "class NaiveBayesClassifier(classificationMethod.ClassificationMethod):\n",
    "  \"\"\"\n",
    "  See the project description for the specifications of the Naive Bayes classifier.\n",
    "  \n",
    "  Note that the variable 'datum' in this code refers to a counter of features\n",
    "  (not to a raw samples.Datum).\n",
    "  \"\"\"\n",
    "  def __init__(self, legalLabels):\n",
    "    self.legalLabels = legalLabels\n",
    "    self.type = \"naivebayes\"\n",
    "    self.k = 1 # this is the smoothing parameter, ** use it in your train method **\n",
    "    self.automaticTuning = False # Look at this flag to decide whether to choose k automatically ** use this in your train method **\n",
    "    \n",
    "  def setSmoothing(self, k):\n",
    "    \"\"\"\n",
    "    This is used by the main method to change the smoothing parameter before training.\n",
    "    Do not modify this method.\n",
    "    \"\"\"\n",
    "    self.k = k\n",
    "\n",
    "  def train(self, trainingData, trainingLabels, validationData, validationLabels):\n",
    "    \"\"\"\n",
    "    Outside shell to call your method. Do not modify this method.\n",
    "    \"\"\"  \n",
    "      \n",
    "    self.features = list(trainingData[0].keys()) # this could be useful for your code later...\n",
    "    \n",
    "    if (self.automaticTuning):\n",
    "        kgrid = [0.001, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 50]\n",
    "    else:\n",
    "        kgrid = [self.k]\n",
    "        \n",
    "    self.trainAndTune(trainingData, trainingLabels, validationData, validationLabels, kgrid)\n",
    "      \n",
    "  def trainAndTune(self, trainingData, trainingLabels, validationData, validationLabels, kgrid):\n",
    "    \"\"\"\n",
    "    Trains the classifier by collecting counts over the training data, and\n",
    "    stores the Laplace smoothed estimates so that they can be used to classify.\n",
    "    Evaluate each value of k in kgrid to choose the smoothing parameter \n",
    "    that gives the best accuracy on the held-out validationData.\n",
    "    \n",
    "    trainingData and validationData are lists of feature Counters.  The corresponding\n",
    "    label lists contain the correct label for each datum.\n",
    "    \n",
    "    To get the list of all possible features or labels, use self.features and \n",
    "    self.legalLabels.\n",
    "    \"\"\"\n",
    "\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    P = util.Counter()\n",
    "    for l in trainingLabels:\n",
    "        P[l] += 1\n",
    "    P.normalize()\n",
    "    self.P = P\n",
    "    \n",
    "    # Initialize stuff\n",
    "    counts = {}\n",
    "    totals = {}\n",
    "    for f in self.features:\n",
    "        counts[f] = {0: util.Counter(), 1: util.Counter()}\n",
    "        totals[f] = util.Counter()\n",
    "                 \n",
    "    # Calculate totals and counts\n",
    "    for i, datum in enumerate(trainingData):\n",
    "        y = trainingLabels[i]\n",
    "        for f, value in list(datum.items()):\n",
    "            counts[f][value][y] += 1.0\n",
    "            totals[f][y] += 1.0 \n",
    "            \n",
    "    bestConditionals = {}\n",
    "    # bestAccuracy = None\n",
    "    bestAccuracy = 0\n",
    "    # Evaluate each k, and use the one that yields the best accuracy\n",
    "    for k in kgrid or [0.0]:\n",
    "        correct = 0\n",
    "        conditionals = {}            \n",
    "        for f in self.features:\n",
    "            conditionals[f] = {0: util.Counter(), 1: util.Counter()}\n",
    "            \n",
    "        # Run Laplace smoothing\n",
    "        for f in self.features:\n",
    "            for value in [0, 1]:\n",
    "                for y in self.legalLabels:\n",
    "                    conditionals[f][value][y] = (counts[f][value][y] + k) / (totals[f][y] + k * 2)\n",
    "            \n",
    "        # Check the accuracy associated with this k\n",
    "        self.conditionals = conditionals              \n",
    "        guesses = self.classify(validationData)\n",
    "        for i, guess in enumerate(guesses):\n",
    "            correct += (validationLabels[i] == guess and 1.0 or 0.0)\n",
    "        accuracy = correct / len(guesses)\n",
    "        \n",
    "        # Keep the best k so far\n",
    "        # if accuracy > bestAccuracy or bestAccuracy is None:\n",
    "        if accuracy > bestAccuracy:\n",
    "          bestAccuracy = accuracy\n",
    "          bestConditionals = conditionals\n",
    "          self.k = k\n",
    "            \n",
    "    self.conditionals = bestConditionals\n",
    "    # util.raiseNotDefined()\n",
    "        \n",
    "  def classify(self, testData):\n",
    "    \"\"\"\n",
    "    Classify the data based on the posterior distribution over labels.\n",
    "    \n",
    "    You shouldn't modify this method.\n",
    "    \"\"\"\n",
    "    guesses = []\n",
    "    self.posteriors = [] # Log posteriors are stored for later data analysis (autograder).\n",
    "    for datum in testData:\n",
    "      posterior = self.calculateLogJointProbabilities(datum)\n",
    "      guesses.append(posterior.argMax())\n",
    "      self.posteriors.append(posterior)\n",
    "    return guesses\n",
    "      \n",
    "  def calculateLogJointProbabilities(self, datum):\n",
    "    \"\"\"\n",
    "    Returns the log-joint distribution over legal labels and the datum.\n",
    "    Each log-probability should be stored in the log-joint counter, e.g.    \n",
    "    logJoint[3] = <Estimate of log( P(Label = 3, datum) )>\n",
    "    \"\"\"\n",
    "    logJoint = util.Counter()\n",
    "    \n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    logJoint = util.Counter()\n",
    "    evidence = datum.items()\n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    for y in self.legalLabels:\n",
    "      logJoint[y] = math.log(self.P[y])\n",
    "      for f in self.conditionals:\n",
    "        prob = self.conditionals[f][datum[f]][y]\n",
    "        logJoint[y] += (prob and math.log(prob) or 0.0)\n",
    "    # util.raiseNotDefined()\n",
    "    \n",
    "    return logJoint\n",
    "  \n",
    "  def findHighOddsFeatures(self, label1, label2):\n",
    "    \"\"\"\n",
    "    Returns the 100 best features for the odds ratio:\n",
    "            P(feature=1 | label1)/P(feature=1 | label2) \n",
    "    \"\"\"\n",
    "    featuresOdds = []\n",
    "        \n",
    "    \"*** YOUR CODE HERE ***\"\n",
    "    for y in self.legalLabels:\n",
    "      logJoint[y] = math.log(self.P[y])\n",
    "      for f in self.conditionals:\n",
    "          prob = self.conditionals[f][datum[f]][y]\n",
    "          logJoint[y] += (prob and math.log(prob) or 0.0)\n",
    "    # util.raiseNotDefined()\n",
    "\n",
    "    return featuresOdds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58695d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
